{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9bf9f1f",
   "metadata": {},
   "source": [
    "#### Загружаем все необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from enum import Enum\n",
    "from keras.utils.all_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.applications.resnet import ResNet50\n",
    "from skimage.color import gray2rgb\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import sys\n",
    "import bbox_visualizer as bbv\n",
    "import segmentation_models as sm\n",
    "from keras.optimizers import adam_v2\n",
    "import keras\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badaf99",
   "metadata": {},
   "source": [
    "#### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_patchify(directory_path, patch_size, add_reflected = False):\n",
    "    \"\"\"\n",
    "    :param patch_size: image patchify square size\n",
    "    :param directory_path: path to root directory containing training and test images\n",
    "    :return: list of images from directory\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize empty list for images\n",
    "    instances = []\n",
    "\n",
    "    # iterate through files in directory\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root,file)\n",
    "            extension = filepath.split(\".\")[-1]\n",
    "            if extension == \"jpg\" or extension == \"png\" or extension == \"bmp\":\n",
    "    \n",
    "                # current image path\n",
    "                img_path = filepath\n",
    "    \n",
    "                # Reads image as BGR\n",
    "                image = cv2.imread(img_path)\n",
    "    \n",
    "                # convert image to RBG\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "                size_x = (image.shape[1] // patch_size) * patch_size  # get width to nearest size divisible by patch size\n",
    "                size_y = (image.shape[0] // patch_size) * patch_size  # get height to nearest size divisible by patch size\n",
    "    \n",
    "                image = Image.fromarray(image)\n",
    "    \n",
    "                # Crop original image to size divisible by patch size from top left corner\n",
    "                image = np.array(image.crop((0, 0, size_x, size_y)))\n",
    "    \n",
    "                # Extract patches from each image, step=patch_size means no overlap\n",
    "                patch_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)\n",
    "    \n",
    "                # iterate over vertical patch axis\n",
    "                for j in range(patch_img.shape[0]):\n",
    "                    # iterate over horizontal patch axis\n",
    "                    for k in range(patch_img.shape[1]):\n",
    "                        # patches are located like a grid. use (j, k) indices to extract single patched image\n",
    "                        single_patch_img = patch_img[j, k]\n",
    "    \n",
    "                        # Drop extra extra dimension from patchify\n",
    "                        instances.append(np.squeeze(single_patch_img))\n",
    "                        if add_reflected == True:\n",
    "                            instances.append(cv2.flip(np.squeeze(single_patch_img), 1))\n",
    "    \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3078ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory_path, size, add_reflected = False):\n",
    "    \"\"\"\n",
    "    :param size: \n",
    "    :param directory_path: path to root directory containing training and test images\n",
    "    :return: list of images from directory\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize empty list for images\n",
    "    instances = []\n",
    "\n",
    "    # iterate through files in directory\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root,file)\n",
    "            extension = filepath.split(\".\")[-1]\n",
    "            if extension == \"jpg\" or extension == \"png\" or extension == \"bmp\":\n",
    "    \n",
    "                # current image path\n",
    "                img_path = filepath\n",
    "    \n",
    "                # Reads image as BGR\n",
    "                image = cv2.imread(img_path)\n",
    "    \n",
    "                # convert image to RBG\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "                image = cv2.resize(image, dsize = [size, size])\n",
    "    \n",
    "                instances.append(image)\n",
    "        \n",
    "                if add_reflected == True:\n",
    "                    instances.append(cv2.flip(image, 1))\n",
    "    \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09aedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_masks(masks, num_classes):\n",
    "    \"\"\"\n",
    "    :param masks: Y_train patched mask dataset \n",
    "    :param num_classes: number of classes\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # initialise list for integer encoded masks\n",
    "    integer_encoded_labels = []\n",
    "\n",
    "    # iterate over each mask\n",
    "    for mask in masks:\n",
    "\n",
    "        # get image shape\n",
    "        _img_height, _img_width, _img_channels = mask.shape\n",
    "\n",
    "        # create new mask of zeros\n",
    "        encoded_image = np.zeros((_img_height, _img_width, 1)).astype(int)\n",
    "\n",
    "        for j, cls in enumerate(MaskColorMap):\n",
    "            encoded_image[np.all(mask == cls.value, axis=-1)] = j\n",
    "\n",
    "        # append encoded image\n",
    "        integer_encoded_labels.append(encoded_image)\n",
    "\n",
    "    # return one-hot encoded labels\n",
    "    return to_categorical(y=integer_encoded_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_index(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true[:,:,:,1])\n",
    "    y_pred_f = K.flatten(y_pred[:,:,:,1])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f)\n",
    "    dice = (2. * intersection + smooth)/(union + smooth)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c83acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true[:,:,:,1])\n",
    "    y_pred_f = K.flatten(y_pred[:,:,:,1])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f)\n",
    "    jaccard = (intersection + smooth) / (union - intersection + smooth)\n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_loss(y_true, y_pred):\n",
    "    loss = 1 - jaccard_index(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9629e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(root_directory, size, patching = False, add_reflected = False):\n",
    "    # initialise lists\n",
    "    image_dataset, mask_dataset = [], []\n",
    "\n",
    "    # define image patch size\n",
    "    #patch_size = 160\n",
    "    # walk through root directory\n",
    "    for path, directories, files in os.walk(root_directory):\n",
    "        for subdirectory in directories:\n",
    "\n",
    "            # extract training input images and patchify\n",
    "            if subdirectory == \"images\":\n",
    "                if patching == True:\n",
    "                    image_dataset.extend(\n",
    "                        load_images_and_patchify(os.path.join(path, subdirectory), patch_size=patch_size, add_reflected = add_reflected))\n",
    "                else:\n",
    "                    image_dataset.extend(\n",
    "                        load_images(os.path.join(path, subdirectory), size=size, add_reflected = add_reflected))\n",
    "\n",
    "            # extract training label masks and patchify\n",
    "            elif subdirectory == \"masks\":\n",
    "                if patching == True:\n",
    "                    mask_dataset.extend(\n",
    "                        load_images_and_patchify(os.path.join(path, subdirectory), patch_size=patch_size, add_reflected = add_reflected))\n",
    "                else:\n",
    "                    mask_dataset.extend(\n",
    "                        load_images(os.path.join(path, subdirectory), size=patch_size, add_reflected = add_reflected))\n",
    "                    \n",
    "    \n",
    "    # return input images and masks\n",
    "    return np.array(image_dataset), np.array(mask_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674276ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(instances, rows=2, titles=None):\n",
    "    \"\"\"\n",
    "    :param instances:  list of images\n",
    "    :param rows: number of rows in subplot\n",
    "    :param titles: subplot titles\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(instances)\n",
    "    cols = n // rows if (n / rows) % rows == 0 else (n // rows) + 1\n",
    "\n",
    "    # iterate through images and display subplots\n",
    "    for j, image in enumerate(instances):\n",
    "        plt.subplot(rows, cols, j + 1)\n",
    "        plt.title('') if titles is None else plt.title(titles[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image)\n",
    "\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_encode_mask(mask):\n",
    "    # initialize rgb image with equal spatial resolution\n",
    "    rgb_encode_image = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    # iterate over MaskColorMap\n",
    "    for j, cls in enumerate(MaskColorMap):\n",
    "        # convert single integer channel to RGB channels\n",
    "        rgb_encode_image[(mask == j)] = np.array(cls.value) / 255.\n",
    "    return rgb_encode_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ecea1",
   "metadata": {},
   "source": [
    "#### Сохраняем маски дверей из json файлов в формате bbox для YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61142af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json to bboxes\n",
    "json_dir = 'C:/ML/Floor/train_dataset_train/object_detection'\n",
    "im_dir = 'C:/ML/Floor/train_dataset_train/train_window/images'\n",
    "out_dir_labels = 'C:/ML/Floor/train_dataset_train/Detection/dataset/labels'\n",
    "out_dir_images = 'C:/ML/Floor/train_dataset_train/Detection/dataset/images'\n",
    "\n",
    "for path, directories, files in os.walk(json_dir):\n",
    "    for file in files:\n",
    "        with open(\"C:/ML/Floor/train_dataset_train/object_detection/\" + file, \"r\") as read_file:\n",
    "            data = json.load(read_file)\n",
    "        image_name = data['imagePath']\n",
    "        try:\n",
    "            img = imread(im_dir + '/' + image_name)\n",
    "        except:\n",
    "            image_name = file.split('.')[0] + '.png'\n",
    "            img = imread(im_dir + '/' + image_name)\n",
    "        imsave(out_dir_images + '/' + image_name, img)\n",
    "        imageHeight = data['imageHeight']\n",
    "        imageWidth = data['imageWidth']\n",
    "        s = img.shape\n",
    "        f = open(out_dir_labels + '/' + image_name.split('.')[0] + '.txt', 'w')\n",
    "        for i in range(len(data['shapes'])):\n",
    "            obj = data['shapes'][i]\n",
    "            if obj['label'] == 'door':\n",
    "                if obj['shape_type'] == 'polygon':\n",
    "                    points = np.int32([obj['points']])\n",
    "                    pt1 = [min(points[0][:,0]), min(points[0][:,1])]\n",
    "                    pt2 = [max(points[0][:,0]), max(points[0][:,1])]\n",
    "                    pt1 = np.array(pt1)\n",
    "                    pt2 = np.array(pt2)\n",
    "                elif obj['shape_type'] == 'rectangle':\n",
    "                    if obj['points'] != []:\n",
    "                        pt1 = np.around(obj['points'][0]).astype(int)\n",
    "                        pt2 = np.around(obj['points'][1]).astype(int)\n",
    "                max_size = max(imageWidth, imageHeight)\n",
    "                if imageHeight == imageWidth:\n",
    "                    pass\n",
    "                elif imageHeight < imageWidth:\n",
    "                    d = round((imageWidth - imageHeight)/2)\n",
    "#                    bbox = [pt1[0], pt1[1]+d, pt2[0], pt2[1]+d]\n",
    "                    pt1[1] = pt1[1]+d\n",
    "                    pt2[1] = pt2[1]+d\n",
    "                else:\n",
    "                    d = round((imageHeight - imageWidth)/2)\n",
    "#                    bbox = [pt1[0]+d, pt1[1], pt2[0]+d, pt2[1]]\n",
    "                    pt1[0] = pt1[0]+d\n",
    "                    pt2[0] = pt2[0]+d\n",
    "                \n",
    "                x = (pt1[0] + (pt2[0] - pt1[0])/2) / max_size\n",
    "                y = (pt1[1] + (pt2[1] - pt1[1])/2) / max_size\n",
    "                w = (pt2[0] - pt1[0]) / max_size\n",
    "                h = (pt2[1] - pt1[1]) / max_size\n",
    "                out_line = '0 ' + str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h)\n",
    "                f.write(out_line + '\\n')\n",
    "        f.close()\n",
    "#        break\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfea99",
   "metadata": {},
   "source": [
    "#### Сегментируем стены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "patch_size = 512\n",
    "\n",
    "class MaskColorMap(Enum):\n",
    "    background = (0, 0, 0)\n",
    "    wall = (255, 255, 255)\n",
    "    \n",
    "data_dir = r\"C:/ML/Floor/train_dataset_train/train_wall\"\n",
    "\n",
    "X, Y = get_training_data(data_dir, patch_size, patching=False, add_reflected=False)\n",
    "\n",
    "m, img_height, img_width, img_channels = X.shape\n",
    "\n",
    "# display images from both training and test sets\n",
    "display_count = 6\n",
    "random_index = [np.random.randint(0, m) for _ in range(display_count)]\n",
    "sample_images = [x for z in zip(list(X[random_index]), list(Y[random_index])) for x in z]\n",
    "display_images(sample_images, rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = one_hot_encode_masks(Y, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wall, X_test_wall, Y_train_wall, Y_test_wall = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925670d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7682cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "BEST_DIR = 'C:/ML/Floor/Results/Attempt_11/wall_segmentation.h5'\n",
    "BACKBONE = 'resnext50'\n",
    "MONITOR = 'val_jaccard_index'\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "N_CLASSES = 2\n",
    "ACTIVATION = 'softmax'\n",
    "SIZE = 512\n",
    "LOSS = jaccard_loss\n",
    "METRICS = jaccard_index\n",
    "\n",
    "model_wall = sm.Unet(BACKBONE, input_shape=(SIZE, SIZE, 3), classes=N_CLASSES, activation=ACTIVATION, encoder_freeze=True, encoder_weights='imagenet')\n",
    "model_wall.compile(adam_v2.Adam(learning_rate=LR), LOSS, METRICS)\n",
    "\n",
    "callbacks = keras.callbacks.ModelCheckpoint(BEST_DIR, monitor=MONITOR, save_weights_only=True, save_best_only=True, mode='max')\n",
    "\n",
    "history = model_wall.fit(X_train_wall, Y_train_wall, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test_wall, Y_test_wall), verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a253f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем предсказанные маски стен\n",
    "for path, directories, files in os.walk('C:/ML/Floor/test_dataset_test'):\n",
    "    for file in files:\n",
    "        filename = file.split(\".\")[0]\n",
    "        filepath = path + '/' + file\n",
    "        img = imread(filepath)\n",
    "        if len(img.shape) == 2:\n",
    "            img = gray2rgb(img)\n",
    "            h, w, c = img.shape\n",
    "        if img.shape[2] == 4:\n",
    "            img = img[:,:,:3]\n",
    "            h, w, c = img.shape\n",
    "        if img.shape[2] == 3:\n",
    "            h, w, c = img.shape\n",
    "        img = cv2.resize(img, dsize = [patch_size, patch_size], interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        img_input = np.expand_dims(img, 0)\n",
    "        \n",
    "        prediction_wall = np.squeeze(model_wall.predict(img_input))\n",
    "        predicted_wall_img = np.argmax(prediction_wall, axis=-1)\n",
    "        predicted_wall_img = cv2.resize(predicted_wall_img, dsize = [w, h], interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        imsave('C:/ML/Floor/Results/Attempt_11/walls/' + file, (predicted_wall_img*255).astype(np.uint8))\n",
    "#        break\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1ecf6",
   "metadata": {},
   "source": [
    "#### Сегментируем окна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25878436",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "BEST_DIR = 'C:/ML/Floor/Results/Attempt_11/window_segmentation.h5'\n",
    "BACKBONE = 'resnext50'\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "N_CLASSES = 2\n",
    "ACTIVATION = 'softmax'\n",
    "SIZE = 512\n",
    "MONITOR = 'val_jaccard_index'\n",
    "LOSS = jaccard_loss\n",
    "METRICS = jaccard_index\n",
    "\n",
    "model_window = sm.Unet(BACKBONE, input_shape=(SIZE, SIZE, 3), classes=N_CLASSES, activation=ACTIVATION, encoder_freeze=True, encoder_weights='imagenet')\n",
    "model_window.compile(adam_v2.Adam(learning_rate=LR), LOSS, METRICS)\n",
    "\n",
    "callbacks = keras.callbacks.ModelCheckpoint(BEST_DIR, monitor=MONITOR, save_weights_only=True, save_best_only=True, mode='max')\n",
    "\n",
    "history = model_window.fit(X_train_window, Y_train_window, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test_window, Y_test_window), verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e951e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем предсказанные маски окон\n",
    "for path, directories, files in os.walk('C:/ML/Floor/test_dataset_test'):\n",
    "    for file in files:\n",
    "        filename = file.split(\".\")[0]\n",
    "        filepath = path + '/' + file\n",
    "        img = imread(filepath)\n",
    "        if len(img.shape) == 2:\n",
    "            img = gray2rgb(img)\n",
    "            h, w, c = img.shape\n",
    "        if img.shape[2] == 4:\n",
    "            img = img[:,:,:3]\n",
    "            h, w, c = img.shape\n",
    "        if img.shape[2] == 3:\n",
    "            h, w, c = img.shape\n",
    "        img = cv2.resize(img, dsize = [patch_size, patch_size], interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        img_input = np.expand_dims(img, 0)\n",
    "        \n",
    "        prediction_window = np.squeeze(model_best.predict(img_input))\n",
    "        predicted_window_img = np.argmax(prediction_window, axis=-1)\n",
    "        predicted_window_img = cv2.resize(predicted_window_img, dsize = [w, h], interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        imsave('C:/ML/Floor/Results/Attempt_11/windows/' + file, (predicted_window_img*255).astype(np.uint8))\n",
    "#        break\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ce3b8",
   "metadata": {},
   "source": [
    "#### Выполним детекцию дверей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переходим в рабочую папку модели YOLO v5\n",
    "%cd C:/ML/Object_detection/Yolo_5/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a18b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем предобученную модель YOLO v5\n",
    "!python train.py --img 512 --batch 2 --epochs 300 --data floor.yaml --weights yolov5l.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f4e11",
   "metadata": {},
   "source": [
    "#### Объединяем результаты сегментации и детекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b014bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, directories, files in os.walk('C:/ML/Floor/Results/Attempt_11/walls'):\n",
    "    for file in files:\n",
    "        filename = file.split(\".\")[0]\n",
    "        filepath = path + '/' + file\n",
    "        wall = imread(filepath)\n",
    "        door = imread('C:/ML/Floor/Results/Attempt_11/doors/' + file)\n",
    "        window = imread('C:/ML/Floor/Results/Attempt_11/windows/' + file)\n",
    "        \n",
    "        s = wall.shape\n",
    "        empty = np.zeros((s[0], s[1])).astype('uint8')\n",
    "        empty[wall==255] = 1\n",
    "        empty[window==255] = 2\n",
    "        empty[door==255] = 3\n",
    "        \n",
    "        imsave('C:/ML/Floor/Results/Attempt_11/images/' + file, empty.astype(np.uint8))\n",
    "#        break\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4bd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
